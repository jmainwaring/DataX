{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.model_selection import GridSearchCV, cross_val_score, train_test_split\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "# from sklearn.model_selection import GridSearchCV, cross_val_score, train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import neighbors\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "from sklearn import grid_search\n",
    "import random\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Defining the filling empty values function </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "def fillEmpty(original_df,colnum,flag):\n",
    "    # assumed: df is the dataframe to operate on,\n",
    "    # colnum is the column number with missing values\n",
    "    # flag = 0/1 is whether it is a classification or regression problem\n",
    "    \n",
    "    # copying the original dataframe\n",
    "    df = original_df.copy()\n",
    "    \n",
    "    # testing for valid flag\n",
    "    if(flag != 0 and flag != 1):\n",
    "        print('Invalid input flag')\n",
    "        sys.exit()\n",
    "    # testing for valid column number\n",
    "    number_of_columns = len(list(original_df))\n",
    "    if(colnum < 0 or colnum >= number_of_columns):\n",
    "        print('Invalid input column number')\n",
    "        sys.exit()\n",
    "    # testing for the existence of empty column values\n",
    "    a = df.iloc[:, [colnum]].isnull()\n",
    "    idx = []\n",
    "    for col in a:\n",
    "        i=0\n",
    "        for c in a[col]:\n",
    "            if(c == True):\n",
    "                idx.append(i)\n",
    "            i=i+1\n",
    "    if(len(idx) == 0):\n",
    "        print('No empty values for input column number')\n",
    "        sys.exit()\n",
    "    \n",
    "    # now can start pre-processing:\n",
    "    # This converts all columns with \"object\" variables (AKA string) into numbers, and creates a dictionary  \n",
    "    char_cols = df.dtypes.pipe(lambda x: x[x == 'object']).index\n",
    "    label_mapping = {}\n",
    "    for c in char_cols:\n",
    "        df[c], label_mapping[c] = pd.factorize(df[c])\n",
    "    # Accessing the rows without empty values at colnum\n",
    "    df_complete = df.dropna()\n",
    "    df_complete.shape\n",
    "    # Accessing the rows with empty values at colnum\n",
    "    df_empty = df.iloc[idx]\n",
    "    df_empty.shape\n",
    "    # Splitting complete rows into target/features\n",
    "    features = df_complete.drop(df.columns[[colnum]], axis=1)\n",
    "    target_variable = df_complete.iloc[:, [colnum]]\n",
    "    # Splitting the rows with empty colnum into features and response (which is what we're predicting)\n",
    "    features_empty = df_empty.drop(df.columns[[colnum]], axis=1)\n",
    "    \n",
    "    # now can start classifying/ predicting:\n",
    "    if(flag==0): # classification\n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "        print('Classifying...')\n",
    "        print()\n",
    "        # Training random forest\n",
    "        randFor = RandomForestClassifier(n_estimators = 20)\n",
    "        randFor.fit(features, target_variable)\n",
    "        # Accuracy on the training set set\n",
    "        print('Training score: ',randFor.score(features, target_variable))\n",
    "        # Set of \"City Group\" predictions for the rows with empty values \n",
    "        y_pred_randFor = randFor.predict(features_empty)\n",
    "        print(y_pred_randFor)\n",
    "    else: # prediction\n",
    "        from sklearn.linear_model import Ridge\n",
    "        print('Predicting...')\n",
    "        print()\n",
    "        # Ridge Regression\n",
    "        ridgereg = Ridge(normalize=True)\n",
    "        ridgereg.fit(features,target_variable)\n",
    "        y_pred_ridge = ridgereg.predict(features_empty)\n",
    "        print (y_pred_ridge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Testing on Restaurant.csv, revenue </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Open Date</th>\n",
       "      <th>City</th>\n",
       "      <th>City Group</th>\n",
       "      <th>Type</th>\n",
       "      <th>P1</th>\n",
       "      <th>P2</th>\n",
       "      <th>P3</th>\n",
       "      <th>P4</th>\n",
       "      <th>P5</th>\n",
       "      <th>...</th>\n",
       "      <th>P29</th>\n",
       "      <th>P30</th>\n",
       "      <th>P31</th>\n",
       "      <th>P32</th>\n",
       "      <th>P33</th>\n",
       "      <th>P34</th>\n",
       "      <th>P35</th>\n",
       "      <th>P36</th>\n",
       "      <th>P37</th>\n",
       "      <th>revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>07/17/1999</td>\n",
       "      <td>İstanbul</td>\n",
       "      <td>Big Cities</td>\n",
       "      <td>IL</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5653753.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>02/14/2008</td>\n",
       "      <td>Ankara</td>\n",
       "      <td>Big Cities</td>\n",
       "      <td>FC</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6923131.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>03/09/2013</td>\n",
       "      <td>Diyarbakır</td>\n",
       "      <td>Other</td>\n",
       "      <td>IL</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2055379.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>02/02/2012</td>\n",
       "      <td>Tokat</td>\n",
       "      <td>Other</td>\n",
       "      <td>IL</td>\n",
       "      <td>6</td>\n",
       "      <td>4.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>7.5</td>\n",
       "      <td>25</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>2675511.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>05/09/2009</td>\n",
       "      <td>Gaziantep</td>\n",
       "      <td>Other</td>\n",
       "      <td>IL</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4316715.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   Open Date        City  City Group Type  P1   P2   P3   P4  P5  \\\n",
       "0   0  07/17/1999    İstanbul  Big Cities   IL   4  5.0  4.0  4.0   2   \n",
       "1   1  02/14/2008      Ankara  Big Cities   FC   4  5.0  4.0  4.0   1   \n",
       "2   2  03/09/2013  Diyarbakır       Other   IL   2  4.0  2.0  5.0   2   \n",
       "3   3  02/02/2012       Tokat       Other   IL   6  4.5  6.0  6.0   4   \n",
       "4   4  05/09/2009   Gaziantep       Other   IL   3  4.0  3.0  4.0   2   \n",
       "\n",
       "     ...      P29  P30  P31  P32  P33  P34  P35  P36  P37    revenue  \n",
       "0    ...      3.0    5    3    4    5    5    4    3    4  5653753.0  \n",
       "1    ...      3.0    0    0    0    0    0    0    0    0  6923131.0  \n",
       "2    ...      3.0    0    0    0    0    0    0    0    0  2055379.0  \n",
       "3    ...      7.5   25   12   10    6   18   12   12    6  2675511.0  \n",
       "4    ...      3.0    5    1    3    2    3    4    3    3  4316715.0  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_df = pd.read_csv(\"Restaurant.csv\")\n",
    "original_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  2267425.,  16549064.,   3376145.,   4067566.,   2097022.,\n",
       "         5435276.,   1756069.,   3008199.,   4316715.,   1734634.,\n",
       "         2383840.,   5017319.,   4264176.,   3753720.,  19696939.,\n",
       "         2740687.,   5595267.,   5525735.,   2018785.,   3447890.,\n",
       "         3982767.,   6694797.,   5337526.,   3600467.,   3351383.,\n",
       "         2544857.,   4651866.,   1270499.,   2058644.,   4219263.])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = original_df.copy()\n",
    "# List of random numbers (no repeats) between 1 and 137 and then delete A_follower_count[that row]   \n",
    "rows_to_delete = random.sample(range(137), 30)\n",
    "# Deleting values from those rows\n",
    "for x in rows_to_delete:\n",
    "    df['revenue'][x] = np.nan\n",
    "# Creating array of the correct answers from original data frame  \n",
    "deleted_answer_list = []\n",
    "for x in rows_to_delete:\n",
    "    deleted_answer_list.append(original_df['revenue'][x])\n",
    "# Converting it to array from a list so we can perform certain calculations\n",
    "deleted_answer_array = np.array(deleted_answer_list)\n",
    "deleted_answer_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting...\n",
      "\n",
      "[[ 3817705.77384499]\n",
      " [ 4728598.14163705]\n",
      " [ 4052049.41928976]\n",
      " [ 4620456.33422125]\n",
      " [ 4264734.68395215]\n",
      " [ 4129408.41800465]\n",
      " [ 4465818.57630399]\n",
      " [ 4057981.35320396]\n",
      " [ 4204132.75542589]\n",
      " [ 3583284.53948341]\n",
      " [ 4614396.83699973]\n",
      " [ 4271192.23781953]\n",
      " [ 4348403.27241239]\n",
      " [ 4112762.90555375]\n",
      " [ 3914225.17760785]\n",
      " [ 4635992.16876365]\n",
      " [ 4728512.36355894]\n",
      " [ 4624400.38770224]\n",
      " [ 4885197.65996617]\n",
      " [ 4005196.49072495]\n",
      " [ 4123320.84794637]\n",
      " [ 4230834.49299511]\n",
      " [ 4956874.4874912 ]\n",
      " [ 5072973.19354393]\n",
      " [ 4113509.03807125]\n",
      " [ 5034484.13433951]\n",
      " [ 4073283.98351226]\n",
      " [ 5125491.58974022]\n",
      " [ 4233604.36083853]\n",
      " [ 4407734.15561198]]\n"
     ]
    }
   ],
   "source": [
    "# test the function\n",
    "fillEmpty(df,42,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Testing on Restaurant.csv, City Group </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Big Cities', 'Big Cities', 'Big Cities', 'Other', 'Big Cities',\n",
       "       'Big Cities', 'Big Cities', 'Big Cities', 'Big Cities', 'Other',\n",
       "       'Big Cities', 'Other', 'Big Cities', 'Other', 'Other', 'Big Cities',\n",
       "       'Other', 'Big Cities', 'Other', 'Big Cities', 'Big Cities', 'Other',\n",
       "       'Other', 'Other', 'Big Cities', 'Big Cities', 'Big Cities', 'Other',\n",
       "       'Big Cities', 'Big Cities'], \n",
       "      dtype='<U10')"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = original_df.copy()\n",
    "# List of random numbers (no repeats) between 1 and 137 and then delete A_follower_count[that row]   \n",
    "rows_to_delete = random.sample(range(137), 30)\n",
    "# Deleting values from those rows\n",
    "for x in rows_to_delete:\n",
    "    df2['City Group'][x] = np.nan\n",
    "# Creating array of the correct answers from original data frame  \n",
    "deleted_answer_list = []\n",
    "for x in rows_to_delete:\n",
    "    deleted_answer_list.append(original_df['City Group'][x])\n",
    "# Converting it to array from a list so we can perform certain calculations\n",
    "deleted_answer_array_city_group = np.array(deleted_answer_list)\n",
    "deleted_answer_array_city_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifying...\n",
      "\n",
      "Training score:  1.0\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1]\n"
     ]
    }
   ],
   "source": [
    "# test the function\n",
    "fillEmpty(df2,3,0) # TODO. problem with cleaning the data when null values exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

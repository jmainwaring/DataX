{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "def fillEmptyNew(original_df,colnum,flag):\n",
    "    # assumed: df is the dataframe to operate on,\n",
    "    # colnum is the column number with missing values\n",
    "    # flag = 0/1 is whether it is a classification or regression problem\n",
    "    \n",
    "    # copying the original dataframe\n",
    "    df = original_df.copy()\n",
    "    \n",
    "    # testing for valid flag\n",
    "    if(flag != 0 and flag != 1):\n",
    "        print('Invalid input flag')\n",
    "        sys.exit()\n",
    "    # testing for valid column number\n",
    "    number_of_columns = len(list(original_df))\n",
    "    # testing for the existence of empty column values\n",
    "    a = df.iloc[:, [colnum]].isnull()\n",
    "    idx = []\n",
    "    for col in a:\n",
    "        i=0\n",
    "        for c in a[col]:\n",
    "            if(c == True):\n",
    "                idx.append(i)\n",
    "            i=i+1\n",
    "    if(len(idx) == 0):\n",
    "        print('No empty values for input column number')\n",
    "        sys.exit()\n",
    "    \n",
    "    # now can start pre-processing:\n",
    "    # This converts all columns with \"object\" variables (AKA string) into numbers, and creates a dictionary  \n",
    "    char_cols = df.dtypes.pipe(lambda x: x[x == 'object']).index\n",
    "    label_mapping = {}\n",
    "    for c in char_cols:\n",
    "        df[c], label_mapping[c] = pd.factorize(df[c])\n",
    "        \n",
    "    # for the sake of classifying/ predicting current column,\n",
    "    # with other columns may having null values,\n",
    "    # we will replace the other columns' null val\n",
    "    for c in df:\n",
    "        df[c] = df[c].fillna(df[c].mean())\n",
    "\n",
    "    # although some issue with the above may arise if null:\n",
    "    # re-set all null values to null\n",
    "    df.iloc[idx,[colnum]] = np.nan\n",
    "    # Accessing the rows without empty values at colnum\n",
    "    df_complete = df.dropna()\n",
    "    df_complete.shape\n",
    "    # Accessing the rows with empty values at colnum\n",
    "    df_empty = df.iloc[idx]\n",
    "    df_empty.shape\n",
    "    # Splitting complete rows into target/features\n",
    "    features = df_complete.drop(df.columns[[colnum]], axis=1)\n",
    "    target_variable = df_complete.iloc[:, [colnum]]\n",
    "    # Splitting the rows with empty colnum into features and response (which is what we're predicting)\n",
    "    features_empty = df_empty.drop(df.columns[[colnum]], axis=1)\n",
    "    \n",
    "    # now can start classifying/ predicting:\n",
    "    y_new = []\n",
    "    if(flag==0): # classification\n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "        print('Classifying...')\n",
    "        print()\n",
    "        # Training random forest\n",
    "        randFor = RandomForestClassifier(n_estimators = 20)\n",
    "        randFor.fit(features, target_variable)\n",
    "        # Accuracy on the training set set\n",
    "        print('Training score: ',randFor.score(features, target_variable))\n",
    "        # Set of \"City Group\" predictions for the rows with empty values \n",
    "        y_new = randFor.predict(features_empty)\n",
    "    else: # prediction\n",
    "        from sklearn.linear_model import Ridge\n",
    "        print('Predicting...')\n",
    "        print()\n",
    "        # Ridge Regression\n",
    "        ridgereg = Ridge(normalize=True)\n",
    "        ridgereg.fit(features,target_variable)\n",
    "        y_new = ridgereg.predict(features_empty)\n",
    "    # add the new values to the dataframe\n",
    "    df.iloc[idx,[colnum]] = y_new\n",
    "    df[colname+'_synthesized'] = 0\n",
    "    df[colname+'_synthesized'][idx] = 1\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Testing on every datatset implemented or given out during lecture this semester.\n",
    "datasets = [\n",
    "'data_modelling.csv',\n",
    "'diabetesdata.csv',\n",
    "'eeg.csv',\n",
    "'Energy.csv',\n",
    "'iris_classification.csv',\n",
    "'test.csv',\n",
    "'train.csv',\n",
    "'yelp.csv']\n",
    "\n",
    "dfs = [pandas.read_csv(i) for i in datasets]\n",
    "\n",
    "# In addition to some datatsets already having NaN values\n",
    "# Empty cells at these determinitistic randomly chosen locations\n",
    "lst = [(1, 1), (0, 1), (1, 3), (1, 6), (4, 0), (4, 2), (4, 3), (4, 6), (5, 0), (5, 2), (5, 3), (5, 6), (8, 0)]\n",
    "for count,df in enumerate(dfs):\n",
    "    for i in lst:\n",
    "            df.set_value(r, c, None)\n",
    "    print(\"Commencing Empty Value Filling For \" + datasets[count])      \n",
    "    fillEmptyNew(df,1,1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Testing on Restaurant.csv\n",
    "In [4]:\n",
    "original_df = pd.read_csv(\"Restaurant.csv\")\n",
    "original_df.head()\n",
    "Out[4]:\n",
    "Id\tOpen Date\tCity\tCity Group\tType\tP1\tP2\tP3\tP4\tP5\t...\tP29\tP30\tP31\tP32\tP33\tP34\tP35\tP36\tP37\trevenue\n",
    "0\t0\t07/17/1999\tİstanbul\tBig Cities\tIL\t4\t5.0\t4.0\t4.0\t2\t...\t3.0\t5\t3\t4\t5\t5\t4\t3\t4\t5653753.0\n",
    "1\t1\t02/14/2008\tAnkara\tBig Cities\tFC\t4\t5.0\t4.0\t4.0\t1\t...\t3.0\t0\t0\t0\t0\t0\t0\t0\t0\t6923131.0\n",
    "2\t2\t03/09/2013\tDiyarbakır\tOther\tIL\t2\t4.0\t2.0\t5.0\t2\t...\t3.0\t0\t0\t0\t0\t0\t0\t0\t0\t2055379.0\n",
    "3\t3\t02/02/2012\tTokat\tOther\tIL\t6\t4.5\t6.0\t6.0\t4\t...\t7.5\t25\t12\t10\t6\t18\t12\t12\t6\t2675511.0\n",
    "4\t4\t05/09/2009\tGaziantep\tOther\tIL\t3\t4.0\t3.0\t4.0\t2\t...\t3.0\t5\t1\t3\t2\t3\t4\t3\t3\t4316715.0\n",
    "5 rows × 43 columns\n",
    "In [34]:\n",
    "df = original_df.copy()\n",
    "# List of random numbers (no repeats) between 1 and 137 and then delete A_follower_count[that row]   \n",
    "rows_to_delete = random.sample(range(137), 30)\n",
    "# Deleting values from those rows\n",
    "for x in rows_to_delete:\n",
    "    df['revenue'][x] = np.nan\n",
    "# Creating array of the correct answers from original data frame  \n",
    "deleted_answer_list = []\n",
    "for x in rows_to_delete:\n",
    "    deleted_answer_list.append(original_df['revenue'][x])\n",
    "# Converting it to array from a list so we can perform certain calculations\n",
    "deleted_answer_array = np.array(deleted_answer_list)\n",
    "deleted_answer_array\n",
    "Out[34]:\n",
    "array([ 3956086.,  3570392.,  6363241.,  7217634.,  3199619.,  4491607.,\n",
    "        3248660.,  4136425.,  2097022.,  3810007.,  2364478.,  3753720.,\n",
    "        7201784.,  3939804.,  3008199.,  4651866.,  3784230.,  2525375.,\n",
    "        4052733.,  6941173.,  8904084.,  3445076.,  6782425.,  4758476.,\n",
    "        3347767.,  1847826.,  4882985.,  4429512.,  1270499.,  2732645.])\n",
    "In [48]:\n",
    "# test the function\n",
    "fillEmpty(df,42,1) # prediction problem\n",
    "Predicting...\n",
    "\n",
    "[[ 4859740.08350571]\n",
    " [ 3728457.71280077]\n",
    " [ 4747301.67852731]\n",
    " [ 3222950.8043993 ]\n",
    " [ 4561678.81569383]\n",
    " [ 4539431.13895401]\n",
    " [ 3997883.59249391]\n",
    " [ 4937836.34377644]\n",
    " [ 5759218.47930182]\n",
    " [ 5509910.54931136]\n",
    " [ 5339310.54251825]\n",
    " [ 5799161.564878  ]\n",
    " [ 4068655.21856287]\n",
    " [ 5832835.33173468]\n",
    " [ 4089367.20097733]\n",
    " [ 4078853.43726617]\n",
    " [ 3968482.16226212]\n",
    " [ 4153452.39903516]\n",
    " [ 4380404.21429641]\n",
    " [ 4164756.72078256]\n",
    " [ 5480252.50591854]\n",
    " [ 4185454.07835212]\n",
    " [ 3779801.40969928]\n",
    " [ 4994081.80228943]\n",
    " [ 4948974.7532436 ]\n",
    " [ 5257586.93332632]\n",
    " [ 5056732.56955768]\n",
    " [ 5426897.76439071]\n",
    " [ 5008856.98454723]\n",
    " [ 5118072.47283297]]\n",
    "In [49]:\n",
    "df2 = original_df.copy()\n",
    "# List of random numbers (no repeats) between 1 and 137 and then delete A_follower_count[that row]   \n",
    "rows_to_delete = random.sample(range(137), 30)\n",
    "# Deleting values from those rows\n",
    "for x in rows_to_delete:\n",
    "    df2['City Group'][x] = np.nan\n",
    "# Creating array of the correct answers from original data frame  \n",
    "deleted_answer_list = []\n",
    "for x in rows_to_delete:\n",
    "    deleted_answer_list.append(original_df['City Group'][x])\n",
    "# Converting it to array from a list so we can perform certain calculations\n",
    "deleted_answer_array_city_group = np.array(deleted_answer_list)\n",
    "deleted_answer_array_city_group\n",
    "Out[49]:\n",
    "array(['Other', 'Big Cities', 'Other', 'Other', 'Other', 'Other', 'Other',\n",
    "       'Big Cities', 'Other', 'Big Cities', 'Other', 'Big Cities',\n",
    "       'Big Cities', 'Other', 'Big Cities', 'Other', 'Other', 'Big Cities',\n",
    "       'Other', 'Big Cities', 'Big Cities', 'Other', 'Big Cities', 'Other',\n",
    "       'Big Cities', 'Big Cities', 'Big Cities', 'Big Cities', 'Other',\n",
    "       'Big Cities'], \n",
    "      dtype='<U10')\n",
    "In [50]:\n",
    "# test the function\n",
    "fillEmpty(df2,3,0) # classification problem\n",
    "Classifying...\n",
    "\n",
    "Training score:  1.0\n",
    "[ 0.  1.  1.  0.  1.  1.  1.  1.  0.  0.  1.  0.  1.  0.  0.  1.  0.  0.\n",
    "  0.  0.  0.  1.  1.  0.  0.  1.  1.  0.  0.  0.]\n",
    "Testing on titanic_with_empties.csv\n",
    "In [51]:\n",
    "titanic_df = pd.read_csv(\"titanic_with_empties.csv\")\n",
    "titanic_df.head()\n",
    "Out[51]:\n",
    "PassengerId\tSurvived\tPclass\tName\tSex\tAge\tSibSp\tParch\tTicket\tFare\tCabin\tEmbarked\n",
    "0\t1\t0.0\t3\tBraund, Mr. Owen Harris\tmale\t22.0\t1\t0\tA/5 21171\t7.2500\tNaN\tS\n",
    "1\t2\t1.0\t1\tCumings, Mrs. John Bradley (Florence Briggs Th...\tfemale\t38.0\t1\t0\tPC 17599\t71.2833\tC85\tC\n",
    "2\t3\tNaN\t3\tHeikkinen, Miss. Laina\tfemale\t26.0\t0\t0\tSTON/O2. 3101282\t7.9250\tNaN\tS\n",
    "3\t4\t1.0\t1\tFutrelle, Mrs. Jacques Heath (Lily May Peel)\tfemale\t35.0\t1\t0\t113803\t53.1000\tC123\tS\n",
    "4\t5\t0.0\t3\tAllen, Mr. William Henry\tmale\t35.0\t0\t0\t373450\t8.0500\tNaN\tS\n",
    "In [52]:\n",
    "# test the function on Cabin\n",
    "fillEmpty(titanic_df,10,0) # classification problem\n",
    "Classifying...\n",
    "\n",
    "Training score:  1.0\n",
    "[  15.   15.    5.  131.    3.    3.    1.   15.   23.    3.    4.    3.\n",
    "    5.    3.    5.    5.    3.    3.   23.   15.  131.   15.    6.  131.\n",
    "    5.    8.   16.   15.   15.    3.    3.    3.    9.    5.   26.    3.\n",
    "   15.    3.  131.   23.    3.    7.   15.    9.   14.   15.   26.    7.\n",
    "   15.    7.  115.    3.   15.    7.   15.   14.    7.   19.    3.   73.\n",
    "   15.   15.   26.   22.   15.   15.  131.   20.   14.    7.    3.   15.\n",
    "   15.   15.   15.   23.   15.   15.   22.   26.   15.   15.   15.   15.\n",
    "   15.   15.   15.   15.   23.    3.   15.    3.    3.   15.  131.   22.\n",
    "    7.   19.   15.   26.    3.   15.   15.   15.   15.   15.    3.   26.\n",
    "   22.   52.   15.    3.   15.    3.   15.   15.   26.   15.    3.   52.\n",
    "   45.   15.    3.   15.   29.   15.   15.   15.    7.    3.   22.   15.\n",
    "   15.   32.   26.    3.   50.    3.    3.    3.   15.    3.    7.   22.\n",
    "   15.    7.   52.    7.    3.    3.   34.    3.   15.   22.   15.    3.\n",
    "  131.    3.  131.   22.   15.    7.   15.   15.   73.    3.    3.    3.\n",
    "   15.   52.   15.   22.    3.    3.   26.   22.   73.   15.   45.   15.\n",
    "   15.   14.   15.   15.    7.   15.   52.    7.   15.   15.   26.   26.\n",
    "   15.   52.    3.    3.   22.   15.   15.   15.  101.   26.   15.    3.\n",
    "    3.    3.   38.  124.   26.  131.    7.  131.   52.    7.   15.   54.\n",
    "   15.   52.  131.   52.   45.    7.   23.  131.   15.   15.   73.   73.\n",
    "   73.   15.   52.    3.   47.    3.   15.   77.   15.  131.   23.   15.\n",
    "   73.   57.   52.   26.   15.   26.   73.   26.   52.   15.   15.   22.\n",
    "   26.    7.   15.   23.    3.    3.   60.   73.   52.   14.   14.   52.\n",
    "   52.   14.    3.   73.   73.    3.    3.   15.   15.   52.   73.   73.\n",
    "   23.   26.   52.   15.    3.   15.   14.  131.   15.   15.   51.    3.\n",
    "    9.   15.   15.   15.  122.    3.   73.   13.   73.   26.    7.   52.\n",
    "  131.   52.   73.   73.   15.   73.   26.   15.   14.   73.   73.    3.\n",
    "    3.   73.   26.  118.   26.   15.    7.   73.  131.   45.   73.   73.\n",
    "   26.   14.   14.    3.   73.   15.   73.    3.    3.   15.   26.   26.\n",
    "  131.   73.   26.   15.    3.   72.   14.   26.   73.   15.   14.   73.\n",
    "   14.   11.    3.   26.   73.   73.   73.   14.  131.   73.   52.   73.\n",
    "   15.   45.   79.  131.    3.   15.   73.   26.   73.   26.   15.   15.\n",
    "    3.    7.   14.   73.   52.    7.   73.    3.   73.   15.   84.   73.\n",
    "    3.   73.   15.   15.  131.  131.    3.   26.   88.   15.    3.  131.\n",
    "   73.   86.   15.  131.   26.   73.   15.   15.   15.  131.   14.   14.\n",
    "   15.   26.   15.   15.    3.   73.   26.   77.   73.    7.    7.   26.\n",
    "  105.   26.   52.   23.   26.   26.  131.   73.   15.  105.   91.   14.\n",
    "  131.   14.   14.   73.   73.   15.   15.    3.   15.   73.   14.  131.\n",
    "   73.   15.   14.   73.   73.   26.   26.   73.   52.   15.   73.   15.\n",
    "  118.  131.   26.   23.   26.   15.   15.   26.   73.   89.   14.  100.\n",
    "  111.   73.  108.   26.    3.   15.    3.  131.   73.   26.   15.    3.\n",
    "   22.   15.   73.   15.  111.   22.   15.  131.  118.  111.    7.   14.\n",
    "   73.   26.    3.   73.   15.    7.   73.    3.   15.   15.   15.   73.\n",
    "   26.   15.  131.  131.    9.   73.    3.   15.    7.  118.  118.   73.\n",
    "    9.   15.   15.  118.  112.  130.   22.   22.   15.   15.   73.    3.\n",
    "  131.   15.    7.   26.  115.    7.   15.   15.    3.   73.   15.   63.\n",
    "  118.  118.  131.   52.  131.   15.   26.   14.  116.    3.   15.   22.\n",
    "  131.   15.   26.   15.   22.   22.   15.    7.  131.   26.    3.    3.\n",
    "   22.   22.   22.  128.    3.   15.   15.  128.  131.    3.   22.  131.\n",
    "   26.  131.   15.   72.   26.   15.   22.  131.   15.   15.   15.   15.\n",
    "  133.  131.  131.  131.   15.  131.  131.   72.   15.    3.  131.  131.\n",
    "  128.   15.   15.   15.    7.    3.  131.   26.    7.  133.   15.   22.\n",
    "  131.  131.    3.   22.   26.   53.   15.   15.   15.   22.   15.  111.\n",
    "  130.    7.  131.  131.   26.  131.    7.  128.  137.    7.  131.    3.\n",
    "   32.  131.  128.   53.  131.   15.   15.   15.  131.   43.   15.   22.\n",
    "   56.  131.   15.  131.    7.  131.   26.    7.  131.    3.   26.  128.\n",
    "  132.    3.  131.  128.   22.    7.   22.   22.   52.  131.    3.   15.\n",
    "  131.   14.   15.   15.   15.  131.   26.  131.   15.   22.   15.  131.\n",
    "   22.   72.  131.]\n",
    "In [53]:\n",
    "# test the function on Survived\n",
    "fillEmpty(titanic_df,1,0) # classification problem\n",
    "Classifying...\n",
    "\n",
    "Training score:  0.991907514451\n",
    "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.\n",
    "  0.  0.  0.  0.  1.  0.  0.  0.]\n",
    "Testing on iris_with_empties.csv\n",
    "In [54]:\n",
    "iris_df = pd.read_csv(\"iris_with_empties.csv\")\n",
    "iris_df.head()\n",
    "Out[54]:\n",
    "sepal_length\tsepal_width\tspecies\n",
    "0\tNaN\t3.5\tsetosa\n",
    "1\t4.9\t3.0\tsetosa\n",
    "2\t4.7\t3.2\tNaN\n",
    "3\t4.6\t3.1\tsetosa\n",
    "4\t5.0\t3.6\tsetosa\n",
    "In [58]:\n",
    "# test the function on sepal_length\n",
    "fillEmpty(iris_df,0,1) # prediction problem\n",
    "Predicting...\n",
    "\n",
    "[[ 5.58385052]\n",
    " [ 5.5814514 ]\n",
    " [ 5.59344702]\n",
    " [ 5.5814514 ]\n",
    " [ 5.57425403]\n",
    " [ 5.867928  ]\n",
    " [ 6.18319407]\n",
    " [ 6.18799232]\n",
    " [ 6.1759967 ]]\n",
    "In [59]:\n",
    "# test the function on species\n",
    "fillEmpty(iris_df,2,0) # classification problem\n",
    "Classifying...\n",
    "\n",
    "Training score:  0.914285714286\n",
    "[ 0.  0.  0.  0.  1.  0.  1.  2.  1.  2.]\n",
    "Testing on energy_with_empties.csv\n",
    "In [60]:\n",
    "energy_df = pd.read_csv(\"energy_with_empties.csv\")\n",
    "energy_df.head()\n",
    "Out[60]:\n",
    "X1\tX2\tX3\tX4\tX5\tX6\tX7\tX8\tY1\n",
    "0\t0.98\t514.5\t294.0\t110.25\t7.0\t2\t0.0\t0\t15.55\n",
    "1\t0.98\t514.5\t294.0\t110.25\t7.0\t3\t0.0\t0\tNaN\n",
    "2\t0.98\t514.5\t294.0\t110.25\t7.0\t4\t0.0\t0\t15.55\n",
    "3\t0.98\t514.5\t294.0\t110.25\t7.0\t5\t0.0\t0\t15.55\n",
    "4\t0.90\t563.5\t318.5\t122.50\t7.0\t2\t0.0\t0\t20.84\n",
    "In [61]:\n",
    "# test the function on Y1\n",
    "fillEmpty(energy_df,8,1) # prediction problem\n",
    "Predicting...\n",
    "\n",
    "[[ 27.65300887]\n",
    " [ 24.87584998]\n",
    " [ 25.78440438]\n",
    " [ 14.38551765]\n",
    " [ 28.78776467]\n",
    " [ 30.32084643]\n",
    " [ 16.97896861]\n",
    " [ 15.43098267]\n",
    " [ 26.9657231 ]\n",
    " [ 16.18810566]\n",
    " [ 28.08441194]\n",
    " [ 27.36951089]\n",
    " [ 17.69993448]\n",
    " [ 17.32018039]\n",
    " [ 31.90703585]\n",
    " [ 32.93583091]\n",
    " [ 28.54489047]\n",
    " [ 29.35342327]\n",
    " [ 16.12444674]\n",
    " [ 18.8320092 ]\n",
    " [ 33.38292355]\n",
    " [ 19.19249214]]\n",
    "Testing on diabetes_with_empties.csv\n",
    "In [6]:\n",
    "diabetes_df = pd.read_csv(\"diabetes_with_empties.csv\")\n",
    "diabetes_df.head()\n",
    "Out[6]:\n",
    "TimesPregnant\tglucoseLevel\tBP\tinsulin\tBMI\tPedigree\tAge\tIsDiabetic\n",
    "0\t6\t148.0\t72\t0\t33.6\t0.627\t50.0\t1\n",
    "1\t1\tNaN\t66\t0\t26.6\t0.351\t31.0\t0\n",
    "2\t8\t183.0\t64\t0\t23.3\t0.672\tNaN\t1\n",
    "3\t1\tNaN\t66\t94\t28.1\t0.167\t21.0\t0\n",
    "4\t0\t137.0\t40\t168\t43.1\t2.288\t33.0\t1\n",
    "In [8]:\n",
    "# test the function on glucoseLevel\n",
    "fillEmpty(diabetes_df,1,1) # prediction problem\n",
    "Predicting...\n",
    "\n",
    "[[ 110.22586021]\n",
    " [ 111.23619473]\n",
    " [ 126.64943274]\n",
    " [ 165.81852911]\n",
    " [ 139.0678635 ]\n",
    " [ 123.74505246]\n",
    " [ 110.25503689]\n",
    " [ 126.02159883]\n",
    " [ 108.0717632 ]\n",
    " [ 118.59162567]\n",
    " [ 131.44741518]\n",
    " [ 108.10021271]\n",
    " [ 129.84577199]\n",
    " [ 129.429291  ]\n",
    " [ 109.19763176]\n",
    " [ 130.82853592]\n",
    " [ 132.6827452 ]\n",
    " [ 120.15041996]\n",
    " [ 140.95280942]\n",
    " [ 133.10629116]\n",
    " [ 109.80068339]\n",
    " [ 123.02784283]\n",
    " [ 116.63436823]\n",
    " [ 134.66353125]\n",
    " [ 106.84183967]\n",
    " [ 107.16755821]\n",
    " [ 114.14224633]\n",
    " [ 120.39957272]\n",
    " [ 120.45788445]\n",
    " [ 130.6438027 ]\n",
    " [ 116.08773432]\n",
    " [ 118.55309261]\n",
    " [ 111.51018416]\n",
    " [ 143.31758113]\n",
    " [ 118.88380431]\n",
    " [ 132.85496529]\n",
    " [ 122.27160436]\n",
    " [ 116.21901929]\n",
    " [ 108.67538893]\n",
    " [ 117.79693612]\n",
    " [ 116.8858277 ]]\n",
    "In [9]:\n",
    "# test the function on age\n",
    "fillEmpty(diabetes_df,6,0) # classification problem\n",
    "Classifying...\n",
    "\n",
    "Training score:  1.0\n",
    "[ 34.  38.  21.  22.  56.  21.  28.  52.  21.  35.  22.  28.  46.  37.  31.\n",
    "  21.  30.  33.  21.  52.  31.  43.  28.  22.  33.  23.  22.  28.  49.  22.\n",
    "  24.  21.  57.  58.  29.  25.  40.  21.  22.  24.  40.]\n",
    "In [33]:\n",
    "# new test: testing the same, but for fillEmpty2\n",
    "fillEmpty2(diabetes_df,'Age',0) # classification problem\n",
    "Classifying...\n",
    "\n",
    "Training score:  1.0\n",
    "[ 36.  33.  25.  22.  67.  21.  28.  26.  25.  58.  22.  22.  46.  37.  22.\n",
    "  21.  29.  23.  21.  52.  28.  21.  28.  21.  33.  24.  24.  24.  39.  25.\n",
    "  37.  24.  57.  37.  29.  25.  31.  21.  22.  24.  42.]\n",
    "In [13]:\n",
    "# new test: testing the same, but for fillEmptyNew\n",
    "fillEmptyNew(diabetes_df,'Age',0) # classification problem\n",
    "Classifying...\n",
    "\n",
    "Training score:  0.998624484182\n",
    "     TimesPregnant  glucoseLevel  BP  insulin   BMI  Pedigree   Age  \\\n",
    "0                6    148.000000  72        0  33.6     0.627  50.0   \n",
    "1                1    121.078404  66        0  26.6     0.351  31.0   \n",
    "2                8    183.000000  64        0  23.3     0.672  45.0   \n",
    "3                1    121.078404  66       94  28.1     0.167  21.0   \n",
    "4                0    137.000000  40      168  43.1     2.288  33.0   \n",
    "5                5    116.000000  74        0  25.6     0.201  30.0   \n",
    "6                3     78.000000  50       88  31.0     0.248  26.0   \n",
    "7               10    115.000000   0        0  35.3     0.134  29.0   \n",
    "8                2    197.000000  70      543  30.5     0.158  53.0   \n",
    "9                8    121.078404  96        0   0.0     0.232  54.0   \n",
    "10               4    110.000000  92        0  37.6     0.191  28.0   \n",
    "11              10    168.000000  74        0  38.0     0.537  34.0   \n",
    "12              10    139.000000  80        0  27.1     1.441  57.0   \n",
    "13               1    121.078404  60      846  30.1     0.398  59.0   \n",
    "14               5    166.000000  72      175  25.8     0.587  51.0   \n",
    "15               7    100.000000   0        0  30.0     0.484  32.0   \n",
    "16               0    121.078404  84      230  45.8     0.551  31.0   \n",
    "17               7    107.000000  74        0  29.6     0.254  31.0   \n",
    "18               1    103.000000  30       83  43.3     0.183  33.0   \n",
    "19               1    115.000000  70       96  34.6     0.529  21.0   \n",
    "20               3    126.000000  88      235  39.3     0.704  27.0   \n",
    "21               8     99.000000  84        0  35.4     0.388  50.0   \n",
    "22               7    196.000000  90        0  39.8     0.451  41.0   \n",
    "23               9    119.000000  80        0  29.0     0.263  29.0   \n",
    "24              11    143.000000  94      146  36.6     0.254  51.0   \n",
    "25              10    125.000000  70      115  31.1     0.205  41.0   \n",
    "26               7    147.000000  76        0  39.4     0.257  43.0   \n",
    "27               1     97.000000  66      140  23.2     0.487  21.0   \n",
    "28              13    121.078404  82      110  22.2     0.245  57.0   \n",
    "29               5    117.000000  92        0  34.1     0.337  38.0   \n",
    "..             ...           ...  ..      ...   ...       ...   ...   \n",
    "738              2     99.000000  60      160  36.6     0.453  24.0   \n",
    "739              1    102.000000  74        0  39.5     0.293  42.0   \n",
    "740             11    120.000000  80      150  42.3     0.785  48.0   \n",
    "741              3    102.000000  44       94  30.8     0.400  26.0   \n",
    "742              1    109.000000  58      116  28.5     0.219  22.0   \n",
    "743              9    140.000000  94        0  32.7     0.734  45.0   \n",
    "744             13    153.000000  88      140  40.6     1.174  39.0   \n",
    "745             12    100.000000  84      105  30.0     0.488  46.0   \n",
    "746              1    147.000000  94        0  49.3     0.358  27.0   \n",
    "747              1     81.000000  74       57  46.3     1.096  32.0   \n",
    "748              3    187.000000  70      200  36.4     0.408  36.0   \n",
    "749              6    162.000000  62        0  24.3     0.178  50.0   \n",
    "750              4    136.000000  70        0  31.2     1.182  22.0   \n",
    "751              1    121.000000  78       74  39.0     0.261  28.0   \n",
    "752              3    108.000000  62        0  26.0     0.223  25.0   \n",
    "753              0    181.000000  88      510  43.3     0.222  26.0   \n",
    "754              8    154.000000  78        0  32.4     0.443  45.0   \n",
    "755              1    128.000000  88      110  36.5     1.057  37.0   \n",
    "756              7    137.000000  90        0  32.0     0.391  39.0   \n",
    "757              0    123.000000  72        0  36.3     0.258  52.0   \n",
    "758              1    106.000000  76        0  37.5     0.197  26.0   \n",
    "759              6    190.000000  92        0  35.5     0.278  66.0   \n",
    "760              2     88.000000  58       16  28.4     0.766  22.0   \n",
    "761              9    170.000000  74        0  44.0     0.403  43.0   \n",
    "762              9     89.000000  62        0  22.5     0.142  33.0   \n",
    "763             10    101.000000  76      180  32.9     0.171  63.0   \n",
    "764              2    122.000000  70        0  36.8     0.340  27.0   \n",
    "765              5    121.000000  72      112  26.2     0.245  37.0   \n",
    "766              1    126.000000  60        0  30.1     0.349  47.0   \n",
    "767              1     93.000000  70        0  30.4     0.315  23.0   \n",
    "\n",
    "     IsDiabetic  Age_synthesized  \n",
    "0             1                0  \n",
    "1             0                0  \n",
    "2             1                1  \n",
    "3             0                0  \n",
    "4             1                0  \n",
    "5             0                0  \n",
    "6             1                0  \n",
    "7             0                0  \n",
    "8             1                0  \n",
    "9             1                0  \n",
    "10            0                1  \n",
    "11            1                0  \n",
    "12            0                0  \n",
    "13            1                0  \n",
    "14            1                0  \n",
    "15            1                0  \n",
    "16            1                0  \n",
    "17            1                0  \n",
    "18            0                0  \n",
    "19            1                1  \n",
    "20            0                0  \n",
    "21            0                0  \n",
    "22            1                0  \n",
    "23            1                0  \n",
    "24            1                0  \n",
    "25            1                0  \n",
    "26            1                0  \n",
    "27            0                1  \n",
    "28            0                0  \n",
    "29            0                0  \n",
    "..          ...              ...  \n",
    "738           0                1  \n",
    "739           1                0  \n",
    "740           1                0  \n",
    "741           0                0  \n",
    "742           0                0  \n",
    "743           1                0  \n",
    "744           0                0  \n",
    "745           0                0  \n",
    "746           1                0  \n",
    "747           0                0  \n",
    "748           1                0  \n",
    "749           1                0  \n",
    "750           1                0  \n",
    "751           0                0  \n",
    "752           0                0  \n",
    "753           1                0  \n",
    "754           1                0  \n",
    "755           1                0  \n",
    "756           0                0  \n",
    "757           1                0  \n",
    "758           0                0  \n",
    "759           1                0  \n",
    "760           0                0  \n",
    "761           1                0  \n",
    "762           0                0  \n",
    "763           0                0  \n",
    "764           0                0  \n",
    "765           0                1  \n",
    "766           1                0  \n",
    "767           0                0  \n",
    "\n",
    "[768 rows x 9 columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

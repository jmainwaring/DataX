{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Cyril/anaconda/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/Cyril/anaconda/lib/python3.6/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.model_selection import GridSearchCV, cross_val_score, train_test_split\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "# from sklearn.model_selection import GridSearchCV, cross_val_score, train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import neighbors\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "from sklearn import grid_search\n",
    "import random\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Defining the filling empty values function </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "def fillEmpty(original_df,colnum,flag):\n",
    "    # assumed: df is the dataframe to operate on,\n",
    "    # colnum is the column number with missing values\n",
    "    # flag = 0/1 is whether it is a classification or regression problem\n",
    "    \n",
    "    # copying the original dataframe\n",
    "    df = original_df.copy()\n",
    "    \n",
    "    # testing for valid flag\n",
    "    if(flag != 0 and flag != 1):\n",
    "        print('Invalid input flag')\n",
    "        sys.exit()\n",
    "    # testing for valid column number\n",
    "    number_of_columns = len(list(original_df))\n",
    "    if(colnum < 0 or colnum >= number_of_columns):\n",
    "        print('Invalid input column number')\n",
    "        sys.exit()\n",
    "    # testing for the existence of empty column values\n",
    "    a = df.iloc[:, [colnum]].isnull()\n",
    "    idx = []\n",
    "    for col in a:\n",
    "        i=0\n",
    "        for c in a[col]:\n",
    "            if(c == True):\n",
    "                idx.append(i)\n",
    "            i=i+1\n",
    "    if(len(idx) == 0):\n",
    "        print('No empty values for input column number')\n",
    "        sys.exit()\n",
    "    \n",
    "    # now can start pre-processing:\n",
    "    # This converts all columns with \"object\" variables (AKA string) into numbers, and creates a dictionary  \n",
    "    char_cols = df.dtypes.pipe(lambda x: x[x == 'object']).index\n",
    "    label_mapping = {}\n",
    "    for c in char_cols:\n",
    "        df[c], label_mapping[c] = pd.factorize(df[c])\n",
    "    # although some issue with the above may arise if null:\n",
    "    # re-set all null values to null\n",
    "    df.iloc[idx,[colnum]] = np.nan\n",
    "    # Accessing the rows without empty values at colnum\n",
    "    df_complete = df.dropna()\n",
    "    df_complete.shape\n",
    "    # Accessing the rows with empty values at colnum\n",
    "    df_empty = df.iloc[idx]\n",
    "    df_empty.shape\n",
    "    # Splitting complete rows into target/features\n",
    "    features = df_complete.drop(df.columns[[colnum]], axis=1)\n",
    "    target_variable = df_complete.iloc[:, [colnum]]\n",
    "    # Splitting the rows with empty colnum into features and response (which is what we're predicting)\n",
    "    features_empty = df_empty.drop(df.columns[[colnum]], axis=1)\n",
    "    \n",
    "    # now can start classifying/ predicting:\n",
    "    if(flag==0): # classification\n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "        print('Classifying...')\n",
    "        print()\n",
    "        # Training random forest\n",
    "        randFor = RandomForestClassifier(n_estimators = 20)\n",
    "        randFor.fit(features, target_variable)\n",
    "        # Accuracy on the training set set\n",
    "        print('Training score: ',randFor.score(features, target_variable))\n",
    "        # Set of \"City Group\" predictions for the rows with empty values \n",
    "        y_pred_randFor = randFor.predict(features_empty)\n",
    "        print(y_pred_randFor)\n",
    "    else: # prediction\n",
    "        from sklearn.linear_model import Ridge\n",
    "        print('Predicting...')\n",
    "        print()\n",
    "        # Ridge Regression\n",
    "        ridgereg = Ridge(normalize=True)\n",
    "        ridgereg.fit(features,target_variable)\n",
    "        y_pred_ridge = ridgereg.predict(features_empty)\n",
    "        print (y_pred_ridge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Testing on Restaurant.csv, revenue </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Open Date</th>\n",
       "      <th>City</th>\n",
       "      <th>City Group</th>\n",
       "      <th>Type</th>\n",
       "      <th>P1</th>\n",
       "      <th>P2</th>\n",
       "      <th>P3</th>\n",
       "      <th>P4</th>\n",
       "      <th>P5</th>\n",
       "      <th>...</th>\n",
       "      <th>P29</th>\n",
       "      <th>P30</th>\n",
       "      <th>P31</th>\n",
       "      <th>P32</th>\n",
       "      <th>P33</th>\n",
       "      <th>P34</th>\n",
       "      <th>P35</th>\n",
       "      <th>P36</th>\n",
       "      <th>P37</th>\n",
       "      <th>revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>07/17/1999</td>\n",
       "      <td>İstanbul</td>\n",
       "      <td>Big Cities</td>\n",
       "      <td>IL</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5653753.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>02/14/2008</td>\n",
       "      <td>Ankara</td>\n",
       "      <td>Big Cities</td>\n",
       "      <td>FC</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6923131.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>03/09/2013</td>\n",
       "      <td>Diyarbakır</td>\n",
       "      <td>Other</td>\n",
       "      <td>IL</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2055379.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>02/02/2012</td>\n",
       "      <td>Tokat</td>\n",
       "      <td>Other</td>\n",
       "      <td>IL</td>\n",
       "      <td>6</td>\n",
       "      <td>4.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>7.5</td>\n",
       "      <td>25</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>2675511.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>05/09/2009</td>\n",
       "      <td>Gaziantep</td>\n",
       "      <td>Other</td>\n",
       "      <td>IL</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4316715.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   Open Date        City  City Group Type  P1   P2   P3   P4  P5  \\\n",
       "0   0  07/17/1999    İstanbul  Big Cities   IL   4  5.0  4.0  4.0   2   \n",
       "1   1  02/14/2008      Ankara  Big Cities   FC   4  5.0  4.0  4.0   1   \n",
       "2   2  03/09/2013  Diyarbakır       Other   IL   2  4.0  2.0  5.0   2   \n",
       "3   3  02/02/2012       Tokat       Other   IL   6  4.5  6.0  6.0   4   \n",
       "4   4  05/09/2009   Gaziantep       Other   IL   3  4.0  3.0  4.0   2   \n",
       "\n",
       "     ...      P29  P30  P31  P32  P33  P34  P35  P36  P37    revenue  \n",
       "0    ...      3.0    5    3    4    5    5    4    3    4  5653753.0  \n",
       "1    ...      3.0    0    0    0    0    0    0    0    0  6923131.0  \n",
       "2    ...      3.0    0    0    0    0    0    0    0    0  2055379.0  \n",
       "3    ...      7.5   25   12   10    6   18   12   12    6  2675511.0  \n",
       "4    ...      3.0    5    1    3    2    3    4    3    3  4316715.0  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_df = pd.read_csv(\"Restaurant.csv\")\n",
    "original_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  4015749.,   3600467.,   1149870.,  13575224.,   4264176.,\n",
       "         7217634.,   3752885.,   2344689.,   3807496.,   4250553.,\n",
       "         2551252.,   3004429.,   8213524.,   4807746.,   2383840.,\n",
       "         2732645.,   2371202.,   4316715.,   1756069.,   4882985.,\n",
       "         3836721.,   2525375.,   2954086.,   5787594.,   5653753.,\n",
       "         2675511.,   4590423.,   9262754.,   4758476.,   3248660.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = original_df.copy()\n",
    "# List of random numbers (no repeats) between 1 and 137 and then delete A_follower_count[that row]   \n",
    "rows_to_delete = random.sample(range(137), 30)\n",
    "# Deleting values from those rows\n",
    "for x in rows_to_delete:\n",
    "    df['revenue'][x] = np.nan\n",
    "# Creating array of the correct answers from original data frame  \n",
    "deleted_answer_list = []\n",
    "for x in rows_to_delete:\n",
    "    deleted_answer_list.append(original_df['revenue'][x])\n",
    "# Converting it to array from a list so we can perform certain calculations\n",
    "deleted_answer_array = np.array(deleted_answer_list)\n",
    "deleted_answer_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting...\n",
      "\n",
      "[[ 4705359.66622173]\n",
      " [ 2861903.54972608]\n",
      " [ 3997522.11962385]\n",
      " [ 5208446.77974179]\n",
      " [ 5136235.94888857]\n",
      " [ 5324599.32264716]\n",
      " [ 4143708.80058126]\n",
      " [ 4818750.79587835]\n",
      " [ 4274971.23788719]\n",
      " [ 4454128.13165543]\n",
      " [ 4732540.28814412]\n",
      " [ 5020942.64806134]\n",
      " [ 4672716.03701595]\n",
      " [ 4817123.41853048]\n",
      " [ 4293130.96551986]\n",
      " [ 4728044.1763354 ]\n",
      " [ 4408222.97492989]\n",
      " [ 3893236.21379395]\n",
      " [ 4290612.92517737]\n",
      " [ 4117917.77606792]\n",
      " [ 5107217.68213713]\n",
      " [ 3788116.57220292]\n",
      " [ 3984277.75379835]\n",
      " [ 2331139.37839418]\n",
      " [ 3034647.74021316]\n",
      " [ 3144454.85480484]\n",
      " [ 4690146.50347888]\n",
      " [ 3589572.74695947]\n",
      " [ 4716656.10619669]\n",
      " [ 4685101.93314578]]\n"
     ]
    }
   ],
   "source": [
    "# test the function\n",
    "fillEmpty(df,42,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Testing on Restaurant.csv, City Group </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Big Cities', 'Other', 'Big Cities', 'Big Cities', 'Big Cities',\n",
       "       'Big Cities', 'Other', 'Other', 'Big Cities', 'Big Cities',\n",
       "       'Big Cities', 'Other', 'Other', 'Other', 'Big Cities', 'Other',\n",
       "       'Other', 'Big Cities', 'Big Cities', 'Big Cities', 'Other', 'Other',\n",
       "       'Other', 'Other', 'Big Cities', 'Other', 'Other', 'Big Cities',\n",
       "       'Other', 'Other'], \n",
       "      dtype='<U10')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = original_df.copy()\n",
    "# List of random numbers (no repeats) between 1 and 137 and then delete A_follower_count[that row]   \n",
    "rows_to_delete = random.sample(range(137), 30)\n",
    "# Deleting values from those rows\n",
    "for x in rows_to_delete:\n",
    "    df2['City Group'][x] = np.nan\n",
    "# Creating array of the correct answers from original data frame  \n",
    "deleted_answer_list = []\n",
    "for x in rows_to_delete:\n",
    "    deleted_answer_list.append(original_df['City Group'][x])\n",
    "# Converting it to array from a list so we can perform certain calculations\n",
    "deleted_answer_array_city_group = np.array(deleted_answer_list)\n",
    "deleted_answer_array_city_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifying...\n",
      "\n",
      "Training score:  1.0\n",
      "[ 0.  1.  0.  1.  1.  0.  1.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.\n",
      "  0.  1.  1.  1.  1.  1.  1.  1.  0.  0.  1.  1.]\n"
     ]
    }
   ],
   "source": [
    "# test the function\n",
    "fillEmpty(df2,3,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
